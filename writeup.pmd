<!--
To run in terminal:
pweave -f pandoc writeup.pmd
pandoc -s --mathjax writeup.md -o writeup.html 
-->

# Analysis of Rule Changes in Subreddits

Namrata Kasaraneni

```python, echo=False
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pprint import pprint

rules = pd.read_csv("output_data/seth/rule_level_data.csv")
sub_metadata = pd.read_csv("output_data/seth/sub_level_data.csv")


def generate_metadata(data, target_field):
    # returns a data frame with rows corresponding to subreddits and columns
    # corresponding to change type
    relevant_columns = data[["communityID", f"{target_field}_change_type"]]
    piv_df = pd.pivot_table(relevant_columns, index=['communityID'], 
                columns=[f"{target_field}_change_type"], aggfunc=len, fill_value=0)
    return piv_df
```
## Data
All of the figures generated in this plot uses data taken from two snapshots of Reddit: 
the first was scraped in April 2020, and the second was scraped December of 2020. Subreddits 
that had fewer than three subscribers in both scrapes, zero rules in both scrapes, or that were 
founded within a month of the first scrape were filtered out. With the remaining
subs, we tracked how rules changed between the two snapshots. We identified rules that
were the same if they had the same creation timestamp and description, or the same rule 
name.

### Categorization of Rule Change
Each rule had a short name (the name displayed on the subreddit's main page) and 
a violation reason (which moderators use to flag posts that violate the rules). Rules have 
to be initialized with a rule name, but can leave the violation reason and description field
blank, or simply copy the rule name into those fields. Violation reasons and descriptions 
that were blank or identical to the rule name were considered missing, since those are 
default values.

Text analysis was done on the version of the rule in the first snapshot and the second snapshot to determine 
how rules in each subreddit changed between snapshots. Each field could be assigned four labels:
unchanged, added, deleted, or changed. Below is a description of how those labels were assigned.

#### Rule Names
1. **unchanged**: Rules that were present in both snapshots, where the Levenshtein distance of the 
                  rule name between snapshots was less than 5.
2. **added**: Rules that were present in the second snapshot and not the first.
3. **deleted**: Rules that were present in the first snapshot and not the second.
4. **changed**: Rules that were present in both snapshots, where the Levenshtein distance of the 
               rule name between snapshots was greater than 5.

#### Rule Descriptions
1. **unchanged**: Rules that had non-default descriptions present in both snapshots, where the Levenshtein distance of the 
                  rule description between snapshots was less than 10.
2. **added**: Rules that only had non-default descriptions present in the second snapshot (either because the rule itself
              was added after the first snapshot, or because a description wasn't added until after the first snapshot).
3. **deleted**: Rules that only had non-default descriptions present in the first snapshot (either because the rule itself
              was deleted after the first snapshot, or because the description was removed after the first snapshot).
4. **changed**: Rules that had non-default descriptions present in both snapshots, where the Levenshtein distance of the 
                rule description between snapshots was greater than 10.

#### Rule Violation Reasons
1. **unchanged**: Rules that had non-default violation reasons present in both snapshots, where the Levenshtein distance of the 
                  violation reason between snapshots was less than 5.
2. **added**: Rules that only had non-default violation reasons present in the second snapshot (either because the rule itself
              was added after the first snapshot, or because a violation reason wasn't added until after the first snapshot).
3. **deleted**: Rules that only had non-default violation reasons present in the first snapshot (either because the rule itself
              was deleted after the first snapshot, or because the violation reason was removed after the first snapshot).
4. **changed**: Rules that had non-default violation reasons present in both snapshots, where the Levenshtein distance of the 
                violation reason between snapshots was greater than 5.



### Description of the dataset

```python, echo = False
rules_metadata = generate_metadata(rules[rules.description_change_type != 'never_present'], "description")
violations_metadata = generate_metadata(rules[rules.violation_change_type != 'never_present'], "violation")
names_metadata = generate_metadata(rules, "name")

rules_per_sub = names_metadata.sum(axis=1)
rule_num_quartiles = sub_metadata.rules_1.quantile([0.25, 0.5, 0.75])
age_quartiles = sub_metadata.age_in_months.quantile([0.25, 0.5, 0.75])
```

The datasets contain <% len(sub_metadata) %> subs. The subs have between <% int(sub_metadata.rules_1.min()) %>
to <% int(sub_metadata.rules_1.max()) %> rules, with the first and third quartiles being <% int(rule_num_quartiles[0.25]) %>
and <% int(rule_num_quartiles[0.75]) %> rules. The subs are between <% int(sub_metadata.age_in_months.min()) %>
to <% int(sub_metadata.age_in_months.max()) %> months old, with the first and third quartiles being 
<% int(age_quartiles[0.25]) %> and <% int(age_quartiles[0.75]) %> months old.

## Growth in Rules Corpus

```python, echo = False, fig = True, width = 400, caption = "Figure 1"
# Get data
data = np.array(rules[rules.description_change_type != 'never_present']["description_change_type"])
labels, counts = np.unique(data, return_counts=True)

# Create histogram
plt.bar(labels, counts, log=True, align='center')
plt.gca().set_xticks(labels)

# Set axis labels and title
plt.xlabel("Change Type")
plt.ylabel("Frequency")
plt.title("How Rule Descriptions Changed Between Snaps")

# Display plot
plt.show()
```

**Figure 1** is a histogram that summarizes the change types of all the rules we processed between
the two snapshots. The vast majority of rules were unchanged between the snapshots. Out of the rules that
had activity, addition was by far the most frequent type of rule activity, followed by deletion.
Actual change of the rule description is the rarest type of rule activity. **Figure 1** indicates that
the overall corpus of subreddit rules is increasing over time. 

## Difference in Changes Between Text Fields


```python, echo = False
added_deleted_rules = rules[(rules.name_change_type == 'added') 
                        | (rules.name_change_type == 'deleted')]
total_added = (added_deleted_rules == 'added').sum()
total_deleted = (added_deleted_rules == 'deleted').sum()
total_present = (added_deleted_rules != 'never_present').sum()
```
In **Table 1**, we can compare the number of non-default rule descriptions and violation reasons
that were present in rules that were either added or deleted between the two snapshots. Rules in Reddit 
have to be initialized with a rule name, but they can leave their violation reasons and rule descriptions
blank, or just make them the same as the rule name. For example, the first row of the table shows that 
<%  total_added['name_change_type'] %> rules were added after the first snapshot, but only 
<%  total_added['description_change_type'] %> of those rules had non-default descriptions.

### Table 1: Added and Deleted Rules 

<style>
  table {
    width: 100%;
    border-collapse: collapse;
  }
  th, td {
    text-align: center;
    padding: 8px;
    border: 1px solid #000;
  }
</style>
<table>
  <tr>
    <th>Change Type</th>
    <th>Rule Name</th>
    <th>Rule Description</th>
    <th>Violation Reason</th>
  </tr>
  <tr>
    <td><strong>added</strong></td>
    <td><% total_added['name_change_type'] %></td>
    <td><% total_added['description_change_type'] %></td>
    <td><% total_added['violation_change_type'] %></td>
  </tr>
  <tr>
    <td><strong>deleted</strong></td>
    <td><% total_deleted['name_change_type'] %></td>
    <td><% total_deleted['description_change_type'] %></td>
    <td><% total_deleted['violation_change_type'] %></td>
  </tr>
  <tr>
    <td><strong>total</strong></td>
    <td><% total_present['name_change_type'] %></td>
    <td><% total_present['description_change_type'] %></td>
    <td><% total_present['violation_change_type'] %></td>
  </tr>
</table>


From the table, we can see that 
<% round(total_added['description_change_type'] / total_added['name_change_type'] * 100, 2) %>%
of added rules had non-default descriptions, and
<% round(total_added['violation_change_type'] / total_added['name_change_type'] * 100, 2) %>%
of them had non-default violation reasons. 
<% int(total_deleted['violation_change_type'] / total_deleted['name_change_type'] * 100) %>%
of the deleted rules had violation reasons.


```python, echo = False
rules_in_both_snaps = rules[(rules.name_change_type != 'added') 
                        & (rules.name_change_type != 'deleted')]
total_unchanged = (rules_in_both_snaps == 'unchanged').sum()
total_added = (rules_in_both_snaps == 'added').sum()
total_deleted = (rules_in_both_snaps == 'deleted').sum()
total_changed = (rules_in_both_snaps == 'changed').sum()
total_present = (rules_in_both_snaps != 'never_present').sum()
```

**Table 2** allows us to examine how different text fields change for rules that are present 
in both snapshots. 
<% round(total_unchanged['description_change_type']/total_present['name_change_type'] * 100, 2) %>%
of these rules were initialized with non-default rule descriptions. Rule descriptions were
never deleted, but
<% round(total_added['description_change_type']/total_present['description_change_type'] * 100, 2) %>%
were added and 
<% round(total_changed['description_change_type']/total_present['description_change_type'] * 100, 2) %>%
were changed. Rule names changed the least often. Violation text saw the most churn, with
<% round(total_added['violation_change_type']/total_present['violation_change_type'] * 100, 2) %>%
 added, 
 <% round(total_deleted['violation_change_type']/total_present['violation_change_type'] * 100, 2) %>%
 deleted and 
<% round(total_changed['violation_change_type']/total_present['violation_change_type'] * 100, 2) %>%
changed.  

### Table 2: Rules That Were Present in Both Snapshots 

<table>
  <tr>
    <th>Change Type</th>
    <th>Rule Name</th>
    <th>Rule Description</th>
    <th>Violation Reason</th>
  </tr>
  <tr>
    <td><strong>unchanged</strong></td>
    <td><% total_unchanged['name_change_type'] %></td>
    <td><% total_unchanged['description_change_type'] %></td>
    <td><% total_unchanged['violation_change_type'] %></td>
  </tr>
  <tr>
    <td><strong>added</strong></td>
    <td><% total_added['name_change_type'] %></td>
    <td><% total_added['description_change_type'] %></td>
    <td><% total_added['violation_change_type'] %></td>
  </tr>
  <tr>
    <td><strong>deleted</strong></td>
    <td><% total_deleted['name_change_type'] %></td>
    <td><% total_deleted['description_change_type'] %></td>
    <td><% total_deleted['violation_change_type'] %></td>
  </tr>
  <tr>
    <td><strong>changed</strong></td>
    <td><% total_changed['name_change_type'] %></td>
    <td><% total_changed['description_change_type'] %></td>
    <td><% total_changed['violation_change_type'] %></td>
  </tr>
  <tr>
    <td><strong>total</strong></td>
    <td><% total_present['name_change_type'] %></td>
    <td><% total_present['description_change_type'] %></td>
    <td><% total_present['violation_change_type'] %></td>
  </tr>
</table>

# Sub Level Hypothesis Testing
## Punctuated Equilibrium

```python, echo=False, caption = "Figure 2", fig = True, width = 400

# get histogram data
histogram_data = rules_metadata.div(rules_metadata.sum(axis=1), axis=0)
histogram_data = histogram_data.multiply(100)
histogram_data['not_unchanged'] = 100 - histogram_data['unchanged']

# Create histogram
plt.hist(histogram_data['not_unchanged'], bins=10)

# Set axis labels and title
plt.xlabel("Percent of Rules Turned Over")
plt.ylabel("Number of Subs")
plt.title("Distribution of Rule Description Turnover per Sub")

# Set y-axis to log scale
plt.yscale("log")

plt.show()
```

**Figure 2** shows a histogram of the percent of rule activity (by either adding, deleting, 
or changing their rule descriptions) for each sub. This plot was generated by finding the percent
of all rule descriptions that were added, deleted, or changed, and the percent that were unchanged. Rules 
that never had non-default descriptions were excluded. <% len(rules_metadata) %> subs had at least one 
rule with a description. 
<% len(histogram_data[histogram_data.not_unchanged < 10]) %> subs turned over less than 10% of their rule descriptions. 
In total, <% len(histogram_data[histogram_data.not_unchanged >= 60]) %> subs turned over at least 60% of their rule 
descriptions between the two snapshots. <% len(histogram_data[histogram_data.not_unchanged >= 90]) %> of those subs turned 
over 90-100% of their rule descriptions.

```python, echo=False, caption = "Figure 3", fig = True, width = 400
# get histogram data
histogram_data = rules_metadata.div(rules_metadata.sum(axis=1), axis=0)
histogram_data = histogram_data.multiply(100)

# Create histogram
plt.hist(histogram_data['changed'], bins=10)

# Set axis labels and title
plt.xlabel("Percent of Rules Changed")
plt.ylabel("Number of Subs")
plt.title("Distribution of Rule Description Changes per Sub")

# Set y-axis to log scale
plt.yscale("log")

plt.show()
```
**Figure 3** is a similar histogram, but only showing rules that had their descriptions changed, discounting 
rules that were added or deleted. <% len(histogram_data[histogram_data['changed'] < 10]) %> 
subs changed less than 10% of their rule descriptions. The evidence has the caveat that subs with high 
percentages of rule changes or activity might in reality have a low count of rules, amplifying the perceived turnover. 

```python, echo=False, caption = "Figure 4", fig = True, width = 400
x = np.array((sub_metadata.added + sub_metadata.deleted + sub_metadata.changed)/sub_metadata.rules_1)
y = np.array(sub_metadata.rules_1)

# Plot the scatter plot with the calculated area
plt.scatter(x, y, alpha=0.3)

plt.xlabel("# Rules Turned Over / # Rules in First Snap")
plt.ylabel("# Rules in First Snap")
plt.title("Rule Turnover and Size of Rule Corpus")

plt.show()
```

**Figure 4** is a scatterplot that looks at the relationship between the number of initial rules 
a sub has and rule turn over (rules that were added, deleted, or changed). 

## Number of Subscribers
### H: The bigger the sub, the more likely that they will add >=1 rule

```python, echo=False, caption = "Figure 5", fig = True, width = 400
# Creating dataset
added = np.array(sub_metadata[sub_metadata.added > 0].subscribers_1)
not_added = np.array(sub_metadata[sub_metadata.added == 0].subscribers_1)
data = np.array([added, not_added], dtype=object)
 
fig = plt.figure()
 
# Creating axes instance
ax = fig.add_axes([0, 0, 1, 1])
 
# Creating plot
bp = ax.boxplot(data,
                 notch=True,  # notch shape
                 vert=False,  # vertical box alignment
                 patch_artist=True,  # fill with color
                 labels=['added >= 1 rule', 'did not add rules'])  # will be used to label x-ticks
plt.xscale("log")

plt.xlabel("# Subscribers")
plt.title("Subreddit Size and Adding a Rule")
plt.show()
```

### H: The bigger the sub, the more likely they will delete >=1 rule
```python, echo=False, caption = "Figure 8", fig = True, width = 400
# Creating dataset
deleted = np.array(sub_metadata[sub_metadata.deleted > 0].subscribers_1)
not_deleted = np.array(sub_metadata[sub_metadata.deleted == 0].subscribers_1)
data = np.array([deleted, not_deleted], dtype=object)
 
fig = plt.figure()
 
# Creating axes instance
ax = fig.add_axes([0, 0, 1, 1])
 
# Creating plot
bp = ax.boxplot(data,
                 notch=True, vert=False, patch_artist=True, 
                 labels=['deleted >= 1 rule', 'did not delete rules'])  # will be used to label x-ticks
plt.xscale("log")

plt.xlabel("# Subscribers")
plt.title("Subreddit Size and Deleting a Rule")
plt.show()
```

### H: the bigger the sub, the more rules they add

```python, echo=False, caption = "Figure 6", fig = True, width = 400
y = np.array(sub_metadata.subscribers_1 + 2)
x = np.array(sub_metadata.added)

# Plot the scatter plot with the calculated area
plt.scatter(x, y, alpha=0.3)
plt.yscale("log")

plt.ylabel("# Subscribers")
plt.xlabel("# Rules Added")
plt.title("Subreddit Size and Rule Additions")

plt.show()
```

### H: the bigger the sub, the more rules they delete

```python, echo=False, caption = "Figure 7", fig = True, width = 400
y = np.array(sub_metadata.subscribers_1 + 2)
x = np.array(sub_metadata.deleted)

# Plot the scatter plot with the calculated area
plt.scatter(x, y, alpha=0.3)
plt.yscale("log")

plt.ylabel("Log # Subscribers")
plt.xlabel("# Rules Deleted")
plt.title("Subreddit Size and Rule Deletions")

plt.show()
```


### H: the bigger the sub, the more total changes they will make
```python, echo=False, caption = "Figure 9", fig = True, width = 400
#     1 scatterplot x = #subscribers, y = sum(rules changed  + rules deleted)
y = np.array(sub_metadata.subscribers_1 + 2)
x = np.array(sub_metadata.deleted + sub_metadata.changed)

# Plot the scatter plot with the calculated area
plt.scatter(x, y, alpha=0.3)
plt.yscale("log")

plt.ylabel("Log # Subscribers")
plt.xlabel("# Rules Changed and Deleted")
plt.title("Subreddit Size and Rule Change")

plt.show()
```


## Age of Sub 
### H: the older the sub, the less likely that they will add >= 1 rule
```python, echo=False, caption = "Figure 10", fig = True, width = 400
# Creating dataset
added = np.array(sub_metadata[sub_metadata.added > 0].age_in_months)
not_added = np.array(sub_metadata[sub_metadata.added == 0].age_in_months)
data = np.array([added, not_added], dtype=object)
 
fig = plt.figure()
 
# Creating axes instance
ax = fig.add_axes([0, 0, 1, 1])
 
# Creating plot
bp = ax.boxplot(data, notch=True, vert=False, patch_artist=True,
                 labels=['added >= 1 rule', 'did not add rules'])  # will be used to label x-ticks

plt.xlabel("Age in Months")
plt.title("Subreddit Age and Adding a Rule")
plt.show()
```

### H: the older the sub, the less likely that they will delete >= 1 rule

```python, echo=False, caption = "Figure 12", fig = True, width = 400
# Creating dataset
deleted = np.array(sub_metadata[sub_metadata.deleted > 0].age_in_months)
not_deleted = np.array(sub_metadata[sub_metadata.deleted == 0].age_in_months)
data = np.array([deleted, not_deleted], dtype=object)
 
fig = plt.figure()
 
# Creating axes instance
ax = fig.add_axes([0, 0, 1, 1])
 
# Creating plot
bp = ax.boxplot(data, notch=True, vert=False,
                 patch_artist=True,  # fill with color
                 labels=['deleted >= 1 rule', 'did not deleted rules'])  # will be used to label x-ticks

plt.xlabel("Age in Months")
plt.title("Subreddit Age and Deleting a Rule")
plt.show()
```

### H: the older the sub, the fewer rules they add
```python, echo=False, caption = "Figure 11", fig = True, width = 400
y = np.array(sub_metadata.age_in_months)
x = np.array(sub_metadata.added)

# Plot the scatter plot with the calculated area
plt.scatter(x, y, alpha=0.3)

plt.ylabel("Age in Months")
plt.xlabel("# Rules Added")
plt.title("Subreddit Age and Rule Additions")

plt.show()
```

### H: the older the sub, the fewer rules they delete

```python, echo=False, caption = "Figure 13", fig = True, width = 400
y = np.array(sub_metadata.age_in_months)
x = np.array(sub_metadata.deleted)

# Plot the scatter plot with the calculated area
plt.scatter(x, y, alpha=0.3)

plt.ylabel("Age in Months")
plt.xlabel("# Rules Deleted")
plt.title("Subreddit Age and Rule Deletions")

plt.show()
```

### H: the older the sub, the fewer total changes they will make
```python, echo=False, caption = "Figure 14", fig = True, width = 400
y = np.array(sub_metadata.age_in_months)
x = np.array(sub_metadata.deleted + sub_metadata.changed)

# Plot the scatter plot with the calculated area
plt.scatter(x, y, alpha=0.3)

plt.ylabel("Age in Months")
plt.xlabel("# Rules Changed or Deleted")
plt.title("Subreddit Age and Rule Change")

plt.show()
```

# Rule Level Hypothesis Testing
### H: the more initial rules the sub has, the more likely they will delete rules
```python, echo=False, caption = "Figure 15", fig = True, width = 400
y = np.array(sub_metadata.age_in_months)
x = np.array(sub_metadata.deleted + sub_metadata.changed)

# Plot the scatter plot with the calculated area
plt.scatter(x, y, alpha=0.3)

plt.ylabel("Age in Months")
plt.xlabel("# Rules Changed or Deleted")
plt.title("Subreddit Age and Rule Change")

plt.show()
```
